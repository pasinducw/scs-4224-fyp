{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4b6f44-b478-4d92-a45f-f060c3a294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "from dataset import getPerformancesList\n",
    "import h5py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c57824a-1127-42d0-8aa5-21723ff3b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAPSHOTS_DIR = \"/home/pasinducw/Documents/research/university-work-scs-4224/comparing-rnn-params/model/model-snapshots/exp15\"\n",
    "SONGS_DIR = \"/home/pasinducw/Downloads/Research-Datasets/covers80/old/covers80_cqt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e256efe-da79-4064-a877-0fa5028f4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_transforms = [\n",
    "        \"_PITCH_SHIFT_0\", \"_PITCH_SHIFT_1\", \"_PITCH_SHIFT_2\", \"_PITCH_SHIFT_3\", \"_PITCH_SHIFT_4\",\n",
    "        \"_TIME_STRETCH_0\", \"_TIME_STRETCH_1\", \"_TIME_STRETCH_2\", \"_TIME_STRETCH_3\", \"_TIME_STRETCH_4\",\n",
    "    ]\n",
    "\n",
    "# Object array of shape {song: string, name: string, path: string} containing the details of performances\n",
    "PERFORMANCES = getPerformancesList(root_dir = SONGS_DIR, excluded_transforms = excluded_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1120f6c3-7783-4c43-bdc0-2325a5b8db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array containing the songs\n",
    "SONGS = []\n",
    "for performance in PERFORMANCES:\n",
    "    SONGS.append(performance['song'])\n",
    "SONGS = np.unique(SONGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc13cc0-b7d6-45b1-b5a8-072ff77a86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model parameters to the PERFORMANCES objects\n",
    "# Resulting object -> { song: string, name: string, path: string, snapshot: OrderedDict, parameters: vector }\n",
    "\n",
    "for (index, performance) in enumerate(PERFORMANCES):\n",
    "    snapshot_location = os.path.join(\n",
    "        SNAPSHOTS_DIR,\n",
    "        '{}-{}'.format(index, performance['name']),\n",
    "        'snapshot-400.pytorch'\n",
    "    )\n",
    "    snapshot = torch.load(snapshot_location)['model_state_dict']\n",
    "    performance['snapshot'] = snapshot # This is an ordered dictionary with model parameters\n",
    "    \n",
    "    parameters = None\n",
    "    for key in snapshot.keys():\n",
    "        values = snapshot[key].flatten()\n",
    "        if parameters is None:\n",
    "            parameters = values\n",
    "        else:\n",
    "            parameters = torch.cat((parameters, values))\n",
    "    performance['parameters'] = parameters # This is a vector that has all the parameters of the model flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f7008b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/pasinducw/Downloads/Research-Datasets/covers80/old/embeddings\"\n",
    "\n",
    "# performance = PERFORMANCES[0]\n",
    "count =0\n",
    "for performance in PERFORMANCES:\n",
    "  count += 1\n",
    "  track_id = performance['name']\n",
    "  work_id = performance['song']\n",
    "  path = os.path.join(DATA_PATH, work_id)\n",
    "  if not os.path.exists(path):\n",
    "      os.makedirs(path)\n",
    "  path = os.path.join(path, \"{}.{}\".format(track_id, 'h5'))\n",
    "#   print(performance['parameters'].numpy().dtype)\n",
    "\n",
    "  with h5py.File(path, \"w\") as f:\n",
    "      embedding = f.create_dataset(\"embedding\", data = performance['parameters'].numpy())\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the metadata\n",
    "METADATA_PATH = \"/home/pasinducw/Downloads/Research-Datasets/covers80/old/embeddings\"\n",
    "path = os.path.join(METADATA_PATH, \"metadata.csv\")\n",
    "with open(path, \"w\") as f:\n",
    "  f.write(\"work_id,track_id\\n\")\n",
    "\n",
    "  for performance in PERFORMANCES:\n",
    "    f.write(\"{},{}\\n\".format(performance['song'], performance['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "778949a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pasinducw/Downloads/Research-Datasets/covers80/old/embeddings/A_Whiter_Shade_Of_Pale/annie_lennox+Medusa+03-A_Whiter_Shade_Of_Pale_WAV.h5\n",
      "['embedding']\n",
      "[-0.04271855  0.55806744 -0.0234014  ... -0.12250717 -0.05396162\n",
      "  0.21084808]\n"
     ]
    }
   ],
   "source": [
    "# Verify the data\n",
    "DATA_PATH = \"/home/pasinducw/Downloads/Research-Datasets/covers80/old/embeddings\"\n",
    "performance = PERFORMANCES[0]\n",
    "\n",
    "track_id = performance['name']\n",
    "work_id = performance['song']\n",
    "path = os.path.join(DATA_PATH, work_id)\n",
    "path = os.path.join(path, \"{}.{}\".format(track_id, 'h5'))\n",
    "print(path)\n",
    "\n",
    "with h5py.File(path, \"r\") as f:\n",
    "  print(list(f.keys()))\n",
    "  data = f['embedding'][:]\n",
    "\n",
    "  \n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
