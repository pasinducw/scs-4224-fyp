{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import PerformanceChunks\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, iterable=(), **kwargs):\n",
    "        self.__dict__.update(iterable, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config({\n",
    "    \"meta_csv\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_annotations_single_1.csv\",\n",
    "    \"dataset_dir\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_features\",\n",
    "    \"feature_type\": \"cqt\",\n",
    "    \"time_axis\": 1,\n",
    "    \"hop_length\": 42,\n",
    "    \"frames_per_sample\": 64,\n",
    "    \"dataset_cache_limit\": 80,\n",
    "    \"workers\": 1,\n",
    "    \"device\": \"cpu\",\n",
    "    \"input_size\": 84,\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size\": 1024,\n",
    "    \"model_layers\": 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENCY IS  0.01179245283018868\n",
      "Input  torch.Size([100, 64, 84])\n",
      "Embeddings  torch.Size([100, 128])\n",
      "Decoder Input 0 torch.Size([100, 1, 84])\n",
      "Decoder state torch.Size([2, 100, 128]) torch.Size([2, 100, 128])\n",
      "Decoder outputs  torch.Size([100, 64, 84])\n",
      "With random decoder inputs\n",
      "torch.Size([100, 64, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7efd8de3edc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = PerformanceChunks(\n",
    "    dataset_meta_csv_path=config.meta_csv,\n",
    "    base_dir=config.dataset_dir,\n",
    "    feature_type=config.feature_type,\n",
    "    time_axis=config.time_axis,\n",
    "    hop_length=config.hop_length,\n",
    "    frames_per_sample=config.frames_per_sample,\n",
    "    cache_limit=config.dataset_cache_limit\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=config.batch_size, num_workers=config.workers, shuffle=False)\n",
    "\n",
    "device = torch.device(config.device)\n",
    "model = Model(input_size=config.input_size, layers=config.model_layers, share_weights=False,\n",
    "              embedding_size=config.hidden_size).to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i, (sequence) in enumerate(dataloader):\n",
    "    sequence = sequence.to(device)\n",
    "    (embeddings, pred) = model(sequence)\n",
    "    print(pred.shape)\n",
    "\n",
    "source = sequence[0] # pred[0]\n",
    "data=source.detach().numpy().transpose()\n",
    "librosa.display.specshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.5514e+00, -5.5144e-01, -1.5514e+00],\n",
       "        [-1.5514e+00, -1.5514e+00, -5.5144e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogSoftmax dimension test\n",
    "d = torch.tensor([[1000.,0.,0.], [0.,1.,0.], [0.,0.,1.]])\n",
    "m = torch.nn.LogSoftmax(dim=1)\n",
    "m(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine wave generation\n",
    "cqt_coefficients, samples = 84, 4200\n",
    "freq = 5/4200\n",
    "\n",
    "steps = np.linspace(0, samples, samples, endpoint=False)\n",
    "wave = np.sin(2 * np.pi * freq * steps)\n",
    "\n",
    "wave = ((wave + 1.0) * ((cqt_coefficients-1)/2))\n",
    "wave = np.floor(wave).astype(int)\n",
    "plot = np.zeros((cqt_coefficients, samples))\n",
    "\n",
    "for (index, value) in enumerate(wave):\n",
    "  plot[value, index] = 1.0\n",
    "\n",
    "librosa.display.specshow(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch View test\n",
    "d = torch.tensor([[[1,2,4], [8, 16, 32]], [[64,128, 256], [512, 1024, 2048]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   1,    2,    4],\n",
       "         [   8,   16,   32]],\n",
       "\n",
       "        [[  64,  128,  256],\n",
       "         [ 512, 1024, 2048]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    4],\n",
       "        [   8,   16,   32],\n",
       "        [  64,  128,  256],\n",
       "        [ 512, 1024, 2048]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.view(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    4],\n",
       "        [   8,   16,   32],\n",
       "        [  64,  128,  256],\n",
       "        [ 512, 1024, 2048]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.view(-1, d.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a):\n",
    "  b = a*a\n",
    "  def test2(v):\n",
    "    return v * b\n",
    "  return test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config({\n",
    "    \"meta_csv\": \"/Users/pasinduwijesena/Downloads/Research-Datasets/covers80/covers80_annotations_single_1.csv\",\n",
    "    \"dataset_dir\": \"/Users/pasinduwijesena/Downloads/Research-Datasets/covers80/covers80_features\",\n",
    "    \"feature_type\": \"cqt\",\n",
    "    \"time_axis\": 1,\n",
    "    \"hop_length\": 42,\n",
    "    \"frames_per_sample\": 64,\n",
    "    \"dataset_cache_limit\": 80,\n",
    "    \"workers\": 1,\n",
    "    \"device\": \"cpu\",\n",
    "    \"input_size\": 84,\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size\": 512,\n",
    "    \"model_layers\": 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PerformanceChunks(\n",
    "    dataset_meta_csv_path=config.meta_csv,\n",
    "    base_dir=config.dataset_dir,\n",
    "    feature_type=config.feature_type,\n",
    "    time_axis=config.time_axis,\n",
    "    hop_length=config.hop_length,\n",
    "    frames_per_sample=config.frames_per_sample,\n",
    "    cache_limit=config.dataset_cache_limit\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=config.batch_size, num_workers=config.workers, shuffle=False)\n",
    "\n",
    "device = torch.device(config.device)\n",
    "model = Model(input_size=config.input_size, layers=config.model_layers, share_weights=False,\n",
    "              embedding_size=config.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 128)\n"
     ]
    }
   ],
   "source": [
    "def build_reference_db(model, dataloader, device, hash_fn):\n",
    "  model.eval()\n",
    "  db = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i, (sequence, sequence_indices, work_id, track_id) in enumerate(dataloader):\n",
    "      sequence = sequence.to(device)\n",
    "      embeddings = model(sequence)\n",
    "\n",
    "      # convert the embeddings to hashes\n",
    "      hashes = hash_fn(embeddings.detach().numpy())\n",
    "      print(hashes.shape)\n",
    "      # save the hashes\n",
    "      for (index, hash) in enumerate(hashes): \n",
    "        db.append([work_id[index], track_id[index], hash])\n",
    "  \n",
    "  return db\n",
    "\n",
    "\n",
    "def hash_fn(embeddings):\n",
    "  def threshold(value):\n",
    "    if value > 0.0:\n",
    "      return True\n",
    "    return False\n",
    "  \n",
    "  vectorized_threshold = np.vectorize(threshold)\n",
    "  return vectorized_threshold(embeddings).astype(bool)\n",
    "\n",
    "\n",
    "ref_db = build_reference_db(model, dataloader, device, hash_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
