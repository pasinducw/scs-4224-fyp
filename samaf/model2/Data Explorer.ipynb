{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import PerformanceChunks\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, iterable=(), **kwargs):\n",
    "        self.__dict__.update(iterable, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config({\n",
    "    \"meta_csv\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_annotations_single_1.csv\",\n",
    "    \"dataset_dir\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_features\",\n",
    "    \"feature_type\": \"cqt\",\n",
    "    \"time_axis\": 1,\n",
    "    \"hop_length\": 42,\n",
    "    \"frames_per_sample\": 64,\n",
    "    \"dataset_cache_limit\": 80,\n",
    "    \"workers\": 1,\n",
    "    \"device\": \"cpu\",\n",
    "    \"input_size\": 84,\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size\": 1024,\n",
    "    \"model_layers\": 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREQUENCY IS  0.01179245283018868\n",
      "Input  torch.Size([100, 64, 84])\n",
      "Embeddings  torch.Size([100, 128])\n",
      "Decoder Input 0 torch.Size([100, 1, 84])\n",
      "Decoder state torch.Size([2, 100, 128]) torch.Size([2, 100, 128])\n",
      "Decoder outputs  torch.Size([100, 64, 84])\n",
      "With random decoder inputs\n",
      "torch.Size([100, 64, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7efd8de3edc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = PerformanceChunks(\n",
    "    dataset_meta_csv_path=config.meta_csv,\n",
    "    base_dir=config.dataset_dir,\n",
    "    feature_type=config.feature_type,\n",
    "    time_axis=config.time_axis,\n",
    "    hop_length=config.hop_length,\n",
    "    frames_per_sample=config.frames_per_sample,\n",
    "    cache_limit=config.dataset_cache_limit\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=config.batch_size, num_workers=config.workers, shuffle=False)\n",
    "\n",
    "device = torch.device(config.device)\n",
    "model = Model(input_size=config.input_size, layers=config.model_layers, share_weights=False,\n",
    "              embedding_size=config.hidden_size).to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i, (sequence) in enumerate(dataloader):\n",
    "    sequence = sequence.to(device)\n",
    "    (embeddings, pred) = model(sequence)\n",
    "    print(pred.shape)\n",
    "\n",
    "source = sequence[0] # pred[0]\n",
    "data=source.detach().numpy().transpose()\n",
    "librosa.display.specshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.5514e+00, -5.5144e-01, -1.5514e+00],\n",
       "        [-1.5514e+00, -1.5514e+00, -5.5144e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogSoftmax dimension test\n",
    "d = torch.tensor([[1000.,0.,0.], [0.,1.,0.], [0.,0.,1.]])\n",
    "m = torch.nn.LogSoftmax(dim=1)\n",
    "m(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sine wave generation\n",
    "cqt_coefficients, samples = 84, 4200\n",
    "freq = 5/4200\n",
    "\n",
    "steps = np.linspace(0, samples, samples, endpoint=False)\n",
    "wave = np.sin(2 * np.pi * freq * steps)\n",
    "\n",
    "wave = ((wave + 1.0) * ((cqt_coefficients-1)/2))\n",
    "wave = np.floor(wave).astype(int)\n",
    "plot = np.zeros((cqt_coefficients, samples))\n",
    "\n",
    "for (index, value) in enumerate(wave):\n",
    "  plot[value, index] = 1.0\n",
    "\n",
    "librosa.display.specshow(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch View test\n",
    "d = torch.tensor([[[1,2,4], [8, 16, 32]], [[64,128, 256], [512, 1024, 2048]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   1,    2,    4],\n",
       "         [   8,   16,   32]],\n",
       "\n",
       "        [[  64,  128,  256],\n",
       "         [ 512, 1024, 2048]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    4],\n",
       "        [   8,   16,   32],\n",
       "        [  64,  128,  256],\n",
       "        [ 512, 1024, 2048]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.view(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    4],\n",
       "        [   8,   16,   32],\n",
       "        [  64,  128,  256],\n",
       "        [ 512, 1024, 2048]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.view(-1, d.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a):\n",
    "  b = a*a\n",
    "  def test2(v):\n",
    "    return v * b\n",
    "  return test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config({\n",
    "    \"reference_csv\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_annotations.csv\",\n",
    "    \"query_csv\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_annotations_single_1.csv\",\n",
    "    \"dataset_dir\": \"/home/pasinducw/Downloads/Research-Datasets/covers80/covers80_features\",\n",
    "    \"feature_type\": \"cqt\",\n",
    "    \"time_axis\": 1,\n",
    "    \"hop_length\": 42,\n",
    "    \"frames_per_sample\": 64,\n",
    "    \"dataset_cache_limit\": 80,\n",
    "    \"workers\": 1,\n",
    "    \"device\": \"cpu\",\n",
    "    \"input_size\": 84,\n",
    "    \"hidden_size\": 128,\n",
    "    \"batch_size\": 512,\n",
    "    \"model_layers\": 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashes_dict(model, dataloader, device, hash_fn):\n",
    "    model.eval()\n",
    "    db = dict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sequence, sequence_indices, work_id, track_id) in dataloader:\n",
    "            sequence = sequence.to(device)\n",
    "            embeddings = model(sequence)\n",
    "\n",
    "            # convert the embeddings to hashes\n",
    "            hashes = hash_fn(embeddings.detach().numpy())\n",
    "\n",
    "            # save the hashes\n",
    "            for (index, hash) in enumerate(hashes):\n",
    "                if hash not in db:\n",
    "                    db[hash] = []\n",
    "                db[hash].append((work_id[index], track_id[index], hash))\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "def build_hash_fn(pivot=0.0):\n",
    "    def threshold(value):\n",
    "        if value > pivot:\n",
    "            return True\n",
    "        return False\n",
    "    vectorized_threshold = np.vectorize(threshold)\n",
    "\n",
    "    def hash_fn(embeddings):\n",
    "        # embeddings -> [batch_size, hidden_size]\n",
    "        batch_size, hidden_size = embeddings.shape\n",
    "        \n",
    "        boolean_values = vectorized_threshold(embeddings).astype(bool)\n",
    "        hashes = np.zeros(batch_size)\n",
    "\n",
    "        for row in range(batch_size):\n",
    "            hash = 0.0\n",
    "            for (index, value) in enumerate(boolean_values[row]):\n",
    "                if value == True:\n",
    "                    hash += 1 << index\n",
    "            hashes[row] = hash\n",
    "\n",
    "        return hashes\n",
    "    return hash_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(config.device)\n",
    "model = Model(\n",
    "  input_size=config.input_size, share_weights=True, \n",
    "  embedding_size=config.hidden_size\n",
    ").to(device)\n",
    "\n",
    "path = \"/home/pasinducw/Documents/research/university-work-scs-4224/samaf/model2/snapshots/cross_entropy_exp1\"\n",
    "model_snapshot = torch.load(\n",
    "  os.path.join(path, \"model.pth\"), map_location=device\n",
    ")\n",
    "model.load_state_dict(model_snapshot[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reference_db(model, device, config):\n",
    "    # Implement\n",
    "    reference_dataset = PerformanceChunks(\n",
    "        dataset_meta_csv_path=config.reference_csv,\n",
    "        base_dir=config.dataset_dir,\n",
    "        feature_type=config.feature_type,\n",
    "        time_axis=config.time_axis,\n",
    "        hop_length=config.hop_length,\n",
    "        frames_per_sample=config.frames_per_sample,\n",
    "        cache_limit=config.dataset_cache_limit,\n",
    "    )\n",
    "    reference_dataloader = torch.utils.data.DataLoader(\n",
    "        reference_dataset, batch_size=config.batch_size, num_workers=config.workers, shuffle=False,\n",
    "    )\n",
    "\n",
    "    reference_db = get_hashes_dict(\n",
    "        model, reference_dataloader, device, build_hash_fn(0.0))\n",
    "    return reference_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = build_reference_db(model, device, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24232"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query using the reference database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_db = ref\n",
    "query_tracks = pd.read_csv(config.query_csv).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for [work_id, track_id] in query_tracks:\n",
    "    query_dataset = PerformanceChunks(\n",
    "        dataset_meta_csv_path=config.query_csv,\n",
    "        base_dir=config.dataset_dir,\n",
    "        feature_type=config.feature_type,\n",
    "        time_axis=config.time_axis,\n",
    "        hop_length=2, # config.hop_length,\n",
    "        frames_per_sample=config.frames_per_sample,\n",
    "        cache_limit=config.dataset_cache_limit,\n",
    "        work_id=work_id,\n",
    "        track_id=track_id,\n",
    "    )\n",
    "\n",
    "    query_dataloader = torch.utils.data.DataLoader(\n",
    "        query_dataset, batch_size=config.batch_size, num_workers=config.workers, shuffle=False,\n",
    "    )\n",
    "\n",
    "    query_hashes = get_hashes_dict(\n",
    "        model, query_dataloader, device, build_hash_fn(0.0),\n",
    "    ).keys()\n",
    "\n",
    "    # Find the matches\n",
    "    matches = dict()\n",
    "    \n",
    "    no_match_count = 0\n",
    "    match_count = 0\n",
    "\n",
    "    for hash in query_hashes:\n",
    "        matched_entries = []\n",
    "        if hash in reference_db:\n",
    "            matched_entries = reference_db[hash]\n",
    "            match_count += 1\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "\n",
    "        for (matched_work_id, matched_track_id, matched_hash) in matched_entries:\n",
    "            if matched_work_id not in matches:\n",
    "                matches[matched_work_id] = 0\n",
    "            matches[matched_work_id] += 1\n",
    "    matches_list = []\n",
    "    for matched_work_id in matches.keys():\n",
    "        matches_list.append((matched_work_id, matches[matched_work_id]))\n",
    "    \n",
    "    dtype = [('work_id', 'S128'), ('matches', int)]\n",
    "    matches_list = np.array(matches_list, dtype=dtype)\n",
    "    matches_list = np.sort(matches_list, order='matches')\n",
    "    matches_list = np.flip(matches_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508 1066\n"
     ]
    }
   ],
   "source": [
    "print(match_count, no_match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'Claudette', 101), (b'Maggie_s_Farm',  58),\n",
       "       (b'What_s_Going_On',  42), (b'Addicted_To_Love',  42),\n",
       "       (b'Night_Time_Is_The_Right_Time',  38), (b'Stone_Cold_Crazy',  35),\n",
       "       (b'I_Don_t_Like_Mondays',  33), (b'Grand_Illusion',  26),\n",
       "       (b'Before_You_Accuse_Me',  26), (b'Walk_This_Way',  25),\n",
       "       (b'Real_Men',  25), (b'Ooby_Dooby',  25), (b'Summer_of_69',  24),\n",
       "       (b'Abracadabra',  23), (b'Summertime_Blues',  22),\n",
       "       (b'River_Deep_Mountain_High',  22),\n",
       "       (b'All_Along_The_Watchtower',  22), (b'September_Gurls',  21),\n",
       "       (b'I_m_Not_In_Love',  21), (b'My_Heart_Will_Go_On',  19),\n",
       "       (b'Blue_Collar_Man',  19), (b'More_Than_Words',  18),\n",
       "       (b'God_Only_Knows',  17), (b'Walking_After_Midnight',  16),\n",
       "       (b'Love_Hurts',  16), (b'Cocaine',  16), (b'Time',  15),\n",
       "       (b'I_Can_t_Get_Next_To_You',  15), (b'Day_Tripper',  15),\n",
       "       (b'Take_Me_To_The_River',  14), (b'No_Woman_No_Cry',  14),\n",
       "       (b'My_Generation',  14), (b'Faith',  13), (b'White_Room',  12),\n",
       "       (b'Purple_Rain',  12), (b'Lady',  11), (b'Yesterday',  10),\n",
       "       (b'Wish_You_Were_Here',  10), (b'Train_In_Vain',  10),\n",
       "       (b'Something_So_Right',  10), (b'New_Age',  10),\n",
       "       (b'I_Love_You',  10), (b'Happiness_is_a_Warm_Gun',  10),\n",
       "       (b'America',  10), (b'Rattlesnakes',   9), (b'Proud_Mary',   9),\n",
       "       (b'Little_Wing',   9), (b'Caroline_No',   9),\n",
       "       (b'I_Don_t_Want_To_Miss_A_Thing',   8),\n",
       "       (b'A_Whiter_Shade_Of_Pale',   8),\n",
       "       (b'Thin_Line_Between_Love_And_Hate',   7), (b'The_Boxer',   7),\n",
       "       (b'Straight_From_The_Heart',   7), (b'Toys_In_The_Attic',   6),\n",
       "       (b'Street_Fighting_Man',   6), (b'Lodi',   6),\n",
       "       (b'I_Can_t_Get_No_Satisfaction',   6), (b'Heart_Of_Gold',   6),\n",
       "       (b'Gold_Dust_Woman',   6), (b'Cecilia',   6),\n",
       "       (b'Red_Red_Wine',   5), (b'Oh_Pretty_Woman',   5),\n",
       "       (b'I_m_Losing_You',   5), (b'All_Tomorrow_s_Parties',   5),\n",
       "       (b'We_Can_Work_It_Out',   4), (b'It_s_Tricky',   4),\n",
       "       (b'Hush',   4), (b'Take_On_Me',   3),\n",
       "       (b'Strange_Little_Girl',   3),\n",
       "       (b'She_Came_In_Through_The_Bathroom_Window',   3),\n",
       "       (b'Never_Let_Me_Down_Again',   3), (b'Enjoy_The_Silence',   3),\n",
       "       (b'Come_Together',   3), (b'Tomorrow_Never_Knows',   2),\n",
       "       (b'Let_It_Be',   2), (b'Waiting_In_Vain',   1), (b'Tush',   1),\n",
       "       (b'Don_t_Let_It_Bring_You_Down',   1), (b'Between_The_Bars',   1)],\n",
       "      dtype=[('work_id', 'S128'), ('matches', '<i8')])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 1127\n"
     ]
    }
   ],
   "source": [
    "print(match_count, no_match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
